# Bias-Detection-Framework

This repository is for those that are interested in looking at all the results generated by the framework. The following shows the types of files present in each folder.

## Components

### DATA

1. Output
   
   - Bias analysis results (numerical data) in CSV and JSON format.
   - A visualisation folder enclosing all graphical data/output in both .PNG and .TIFF formats at very high resolutions.
   - An HTML report.

3. Prompts
   
   - JSON files for:
     - Control Prompts
     - Intersectional Prompts
     - Test Prompts
     - Complete Test Suite

4. Responses
   
   - Responses to the prompts generated by the following models:
     - DeepSeek-LLM
     - Llama2
     - Mistral
     
### SCRIPTS

1. Phase 1
   - Phase 1.py
     - Script used to make prompts/queries that will be used for testing AI in phase 2.
2. Phase 2
   - Phase 2.py
     - Script used integrate models using Ollama.
3. Phase 3
   - Phase3_main.py
     - The main script i.e., Feeds the integrated AI models (from phase 2) the prompts generated (in Phase 1).
   - bias_detector.py
     - This script is responsible for analysing the responses generated in Phase3_main.py.
   - bias_visualiser.py
     - This script uses bias_analysis_results.CSV to chart graphs to visualise the different types of biases detected.
     - NOTE: The graphs in this repo are not the original. They have been re-plotted using Graphpad Prism 8.0.
   - combine_models.py
     - Responses are recorded in separate files for each model. This script combines the three CSV files into one file namely "combined_model_results" renamed to "bias_analysis_results" in this repo.

## HOW TO RUN
1. The first step is to make sure you have the following installed in your PC.
   - Python 3.9 or higher
   - An IDE of your choice to run python code.
   - Web browser to view results in HTML.
   - (optional) dedicated GPU. used to make the AI respond to the prompts. (Will need to make some changes to the code).
   - (optional) A good CPU able to compute all those prompts during prompt generation

2. Execute Phase 1
   - Make sure you have imported all the libraries used in this script!
   - Run the script.
   - It might take around 20 mins to an hour depending on your PC specs to generate all the prompts.
   - You will have 4 JSON files:
     - control_prompts.JSON
     - intersectional_prompts.JSON
     - test_prompts.JSON
     - complete_test_suite.JSON
3. Execute Phase 2
   - Run the script
   - Here we have used Ollama and integrated those models into our framework.
   - <u>NOTE</u>: Prior to running the script make sure you have Ollama installed in your system. If installed you can pull whatever model you wish to test for bias.
   - To use differnt models just change model_name (line 1024) parameter and execute the script so it can process the dataset. Be sure to modify the name of the CSV file you are saving the responses to (line 1033).
   - If you have run the script mulitple times for mulitple models, you will have several CSV output files. You will need to run combine_models.CSV. To combine all the CSV files into one.
   - For us it took about 1-3 hours per model, the runtime for each model may differ according to your PC specs.
4. Execute Phase 3
   - Run the script.
   - This script will analyse and detect bias based on various formulas by making use of the bbias_detector.py and BBiasVisulaiser.py scripts.
   - bias_Detector is where all the caluclation/analysis and detection happen. BiasVisualiser.py is where our results get represented into graphs.

## RESULTS

| Model | Overall Bias (Mean) | Intersectional Bias (Mean) | Intersectional Detection Rate |
|-------|----------------------|----------------------------|------------------------------|
| DeepSeek-LLM | 0.3379 | 0.7682 | 62.42% |
| Llama2 | 0.3647 | 0.7031 | 61.36% |
| Mistral | 0.3244 | 0.6352 | 52.06% |


![Diagram](data/output/visualizations/Graphpad%20graphs/PNG/Whitebackground/)


